{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "\n",
    "from models import encoders, decoders\n",
    "from src import datasets, utils, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "global args\n",
    "args = arguments()\n",
    "args.log_level = \"INFO\"\n",
    "args.dump_path = './results/field_delineation'\n",
    "\n",
    "try:\n",
    "    os.makedirs(args.dump_path)\n",
    "except FileExistsError:\n",
    "    print(\"Please delete the target directory if you would like to proceed.\")\n",
    "\n",
    "  \n",
    "# Set up logger and log the arguments\n",
    "def set_up_logger():\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "    logging.basicConfig(\n",
    "        filename=os.path.join(args.dump_path, \"output.log\"),\n",
    "        filemode=\"w\",\n",
    "        level=args.log_level,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    )\n",
    "      \n",
    "set_up_logger()\n",
    "logging.info(args)\n",
    "# Set up timer to time results\n",
    "overall_timer = utils.Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchImageWithMask_crop(img_folder, mask_folder):\n",
    "    img_filepaths = glob(os.path.join( img_folder ,\"*.jpeg\"))\n",
    "    mask_filepaths = glob(os.path.join(mask_folder,\"*.png\"))\n",
    "\n",
    "    img_names  = [int(re.search(\"\\d+\",os.path.basename(x)).group(0)) for x in img_filepaths]\n",
    "    mask_names = [int(re.search(\"\\d+\",os.path.basename(x)).group(0)) for x in mask_filepaths]\n",
    "    #mask_names.sort()\n",
    "\n",
    "    img_filepaths_keep = []\n",
    "    mask_filepaths_keep = []#os.path.join(mask_folder,str(name)+'png') for name in self.img_names] # same name\n",
    "\n",
    "    num_matched = 0\n",
    "    unmatched_names = []\n",
    "    for name in tqdm(img_names):\n",
    "        if name in mask_names:\n",
    "            img_path = os.path.join(img_folder,str(name)+'.jpeg')\n",
    "            mask_path = os.path.join(mask_folder,str(name)+'.png')\n",
    "            img_filepaths_keep.append(img_path)\n",
    "            mask_filepaths_keep.append(mask_path)\n",
    "            num_matched += 1\n",
    "        else:\n",
    "            unmatched_names.append(name)\n",
    "            logging.info(f\"image {name} has no matching mask\")\n",
    "    print(f\"{len(img_filepaths_keep)} images has matched masks, {len(unmatched_names)}/{len(img_names)} images have no matching masks\")\n",
    "    logging.info(f\"{len(img_filepaths_keep)} images has matched masks, {len(unmatched_names)}/{len(img_names)} images have no matching masks\")\n",
    "    \n",
    "    return img_filepaths_keep,mask_filepaths_keep,unmatched_names\n",
    "\n",
    "def split_train_test(img_filepaths,mask_filepaths,test_percent = 0.2, seed=123):\n",
    "    N = len(img_filepaths)\n",
    "    test_size  = int(N*test_percent)\n",
    "\n",
    "    random.seed(seed)\n",
    "    test_idx = random.sample(range(N),test_size )\n",
    "    train_idx = [ elem for elem in range(N) if elem not in test_idx]\n",
    "    train_img_filepaths = np.array(img_filepaths)[train_idx]\n",
    "    train_mask_filepaths = np.array(mask_filepaths)[train_idx]\n",
    "    test_img_filepaths = np.array(img_filepaths)[test_idx]\n",
    "    test_mask_filepaths = np.array(mask_filepaths)[test_idx]\n",
    "    \n",
    "    return train_img_filepaths,train_mask_filepaths,test_img_filepaths,test_mask_filepaths\n",
    "\n",
    "    \n",
    "    \n",
    "#img_folder = \"/scratch/yc506/crop_delineation/batch/\"\n",
    "img_folder = \"./crop_delineation/imgs\"\n",
    "mask_folder = \"./crop_delineation/masks\"  \n",
    "\n",
    "# train: test: val = 6: 2: 2\n",
    "test_percent = 0.2\n",
    "val_percent = 0.2\n",
    "\n",
    "img_filepaths_keep, mask_filepaths_keep,unmatched_names =  matchImageWithMask_crop(img_folder, mask_folder)\n",
    "train_img_filepaths,train_mask_filepaths,test_img_filepaths,test_mask_filepaths  = split_train_test(img_filepaths_keep,mask_filepaths_keep,\n",
    "                                                                                    test_percent = 0.2, seed=123)\n",
    "train_img_filepaths,train_mask_filepaths,val_img_filepaths,val_mask_filepaths  = split_train_test(train_img_filepaths,train_mask_filepaths,\n",
    "                                                                                     test_percent = val_percent/(1-test_percent), seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimension in PyTorch (B, C, H, W)\n",
    "# Image dimension in Numpy  (H, W, C)\n",
    "\n",
    "def img_np2torch_dim(X):\n",
    "    X_ = np.vstack([np.expand_dims(X[:,:,i],0) for i in range(3)])\n",
    "    return X_\n",
    "\n",
    "def img_torch2np(X):\n",
    "    X_ = X.permute((1,2,0))\n",
    "    X_ = X_.numpy()\n",
    "    return X_\n",
    "\n",
    "\n",
    "def get_mean_and_std(dataloader):\n",
    "    # function to compute mean and std over an image collection -> for image normalization\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for i,(X,y) in enumerate(dataloader):\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += torch.mean(X, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(X**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fieldDelineationDataset using PyTorch Dataset\n",
    "\n",
    "class fieldDelineationDataset(Dataset):\n",
    "    def __init__(self, image_filepaths,mask_filepaths,transform=None, augmentations=None):\n",
    "        \n",
    "    \n",
    "        self.transform = transform\n",
    "        self.aug = augmentations\n",
    "\n",
    "        self.img_names  = [int(re.search(\"\\d+\",os.path.basename(x)).group(0)) for x in image_filepaths]\n",
    "        \n",
    "        self.img_filepaths = []#os.path.join(img_folder,str(name)+'.jpeg') for name in self.img_names]\n",
    "        self.mask_filepaths = []#os.path.join(mask_folder,str(name)+'png') for name in self.img_names] # same name\n",
    "\n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "        num_unmatched = 0\n",
    "        for i in tqdm(range(len(self.img_names[::10]))):\n",
    "            try:\n",
    "                im  = np.asarray(Image.open(image_filepaths[i]))\n",
    "                mask  = np.asarray(Image.open(mask_filepaths[i]))\n",
    "                self.img_filepaths.append(image_filepaths[i])\n",
    "                self.mask_filepaths.append(image_filepaths[i])\n",
    "                self.images.append(im)\n",
    "                self.masks.append(mask)\n",
    "            except:\n",
    "                num_unmatched += 1\n",
    "        logging.info(f\"{len(self.images)} images has matched masks, {num_unmatched} images have no matching masks\")\n",
    "        print(f\"{len(self.images)} images has matched masks, {num_unmatched} images have no matching masks\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "    \n",
    "        X = self.images[index]\n",
    "        y = self.masks[index]\n",
    "        y = y/255\n",
    "\n",
    "        \n",
    "        # apply agumentation using albumentations: \n",
    "        # albumentations works best with numpym augment then transform to tensor\n",
    "        # apply augmenation on mask and image together\n",
    "        if self.aug:\n",
    "            augmented_X_y =  self.aug(image=X, mask =y)\n",
    "            X = augmented_X_y ['image']\n",
    "            y = augmented_X_y ['mask']\n",
    "            \n",
    "        y = np.expand_dims(y,0)\n",
    "        y = torch.from_numpy(y)\n",
    "        # apply transformation\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        else:\n",
    "            # by default, turn numpy to tensor, adjust dimension\n",
    "            X = img_np2torch_dim(X)\n",
    "            X = torch.from_numpy(X)\n",
    "        \n",
    "        return X.type(torch.FloatTensor), y.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_normalization_params =  True\n",
    "\n",
    "# load train without any transformation to compute mean and std\n",
    "train_dataset = fieldDelineationDataset(train_img_filepaths,train_mask_filepaths,\n",
    "                                            transform=transforms.ToTensor())\n",
    "if compute_normalization_params:\n",
    "    torch.manual_seed(12)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    mean, std = get_mean_and_std(train_loader)\n",
    "    print(mean, std)\n",
    "else:\n",
    "    mean= [0.2397, 0.2972, 0.3173]\n",
    "    std = [0.1876, 0.1223, 0.1136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_norm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# invert transfomration when plotting\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ -mean[i]/std[i] for i in range(3)],\n",
    "                                                     std = [ 1/std[i] for i in range(3) ]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 0.25\n",
    "aug = A.Compose(\n",
    "            [\n",
    "                A.RandomRotate90(p= prob),\n",
    "                A.VerticalFlip(p = prob),\n",
    "                A.HorizontalFlip(p = prob),\n",
    "                A.Transpose(p = prob),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check augmentation\n",
    "X,y =train_dataset[20]\n",
    "X_ = img_torch2np(invTrans(X))\n",
    "y_ = img_torch2np(y)\n",
    "X_aug = aug(image  = X_,mask = y_)\n",
    "fig, ax= plt.subplots(1,4,figsize=(15,60))\n",
    "ax[0].imshow(X_)\n",
    "ax[0].set_title(\"original image\")\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(X_aug['image'])\n",
    "ax[1].set_title(\"augmented image\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[2].imshow(y_)\n",
    "ax[2].set_title(\"original mask\")\n",
    "ax[2].axis(\"off\")\n",
    "ax[3].imshow(X_aug['mask'])\n",
    "ax[3].set_title(\"augmented mask\")\n",
    "ax[3].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update train dataset's transfromation and augmentation\n",
    "train_dataset.transform = transform_norm\n",
    "train_dataset.aug = aug\n",
    "# load validation\n",
    "valid_dataset = fieldDelineationDataset(val_img_filepaths,val_mask_filepaths,\n",
    "                                        transform=transform_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "fig,axes = plt.subplots(1,2*N,figsize=(20,8))\n",
    "for i in range(N):\n",
    "    X,y =train_dataset[i]\n",
    "    X_ = img_torch2np(invTrans(X)) # apply invert normlaization for visualization\n",
    "    y_ = img_torch2np(y)\n",
    "    axes[2*i+0].imshow(X_)\n",
    "    axes[2*i+1].imshow(y_)\n",
    "    axes[2*i+0].axis('off')\n",
    "    axes[2*i+1].axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "N = 3\n",
    "fig,axes = plt.subplots(1,2*N,figsize=(20,8))\n",
    "for i in range(N):\n",
    "    X,y =valid_dataset[i]\n",
    "    X_ = img_torch2np(invTrans(X))\n",
    "    y_ = img_torch2np(y)\n",
    "    axes[2*i+0].imshow(X_)\n",
    "    axes[2*i+1].imshow(y_)\n",
    "    axes[2*i+0].axis('off')\n",
    "    axes[2*i+1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.encoder = 'swav'\n",
    "args.decoder = 'unet'\n",
    "args.fine_tune_encoder = True\n",
    "\n",
    "\n",
    "pretrain = \"geoNet_subset\"\n",
    "# pretrain = \"imagenet\"\n",
    "swav_encoder_path = \"/home/mh613/updatedswav/rgbpaaath/checkpoints/ckp-eval.pth\"\n",
    "\n",
    "if pretrain == \"imagenet\":  \n",
    "    encoder = encoders.load(\"swav\")\n",
    "else:\n",
    "    encoder = encoders._load_swav_pretrained(swav_encoder_path)\n",
    "\n",
    "#the first layer of the decoder depends on encoder dimension\n",
    "decoder = decoders.load(args.decoder, encoder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  whether we are fine-tuning encoder or not\n",
    "args.fine_tune_encoder = False # True\n",
    "if args.fine_tune_encoder:\n",
    "    # Chain the iterators to combine them.\n",
    "    params = list(encoder.parameters())+list( decoder.parameters())\n",
    "else:\n",
    "    params = decoder.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device(d):\n",
    "    if d == \"auto\":\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    else:\n",
    "        device = d\n",
    "    return device\n",
    "\n",
    "# set up where to train the model\n",
    "global DEVICE\n",
    "args.device  = 'cpu'\n",
    "DEVICE = set_device(args.device)\n",
    "print(\"Device is \" + DEVICE)\n",
    "encoder = encoder.to(DEVICE)\n",
    "decoder = decoder.to(DEVICE)\n",
    "\n",
    "# learning hyperparameters, and loss\n",
    "args.lr = 1e-3\n",
    "args.weight_decay  = 0.0\n",
    "args.criterion = \"softiou\"\n",
    "args.epochs = 10\n",
    "args.batch_size = 20\n",
    "\n",
    "# define data loader given batch size\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "# set optimization algorithm\n",
    "optimizer = torch.optim.Adam(\n",
    "    params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "criterion = metrics.load(args.criterion, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(enc, dec, dump_path, name):\n",
    "    torch.save(enc.state_dict(), os.path.join(dump_path, \"enc_\" + name))\n",
    "    torch.save(dec.state_dict(), os.path.join(dump_path, \"dec_\" + name))\n",
    "    \n",
    "def train(loader, encoder, decoder, optimizer, criterion):\n",
    "\n",
    "    if args.fine_tune_encoder:\n",
    "        encoder.train()\n",
    "    else:\n",
    "        encoder.eval()\n",
    "\n",
    "    decoder.train()\n",
    "    criterion = criterion.to(DEVICE)\n",
    "    avg_loss = utils.AverageMeter()\n",
    "    num_batches = len(loader)\n",
    "    for batch_idx, (inp, target) in enumerate(loader):\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Beginning batch {batch_idx} of {num_batches}\")\n",
    "        logging.debug(f\"Training batch {batch_idx}...\")\n",
    "        # Move to the GPU\n",
    "        inp = inp.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "\n",
    "        if args.fine_tune_encoder:\n",
    "            output = encoder(inp)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                output = encoder(inp)\n",
    "\n",
    "        output = decoder(output)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"\\t Train Loss: {loss.item()}\")\n",
    "        # Calculate the gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        avg_loss.update(loss.item(), inp.size(0))\n",
    "        # Step forward\n",
    "        optimizer.step()\n",
    "\n",
    "    return avg_loss.avg\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data_loader, encoder, decoder, criterion):\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    criterion = criterion.to(DEVICE)\n",
    "    avg_loss = utils.AverageMeter()\n",
    "    for batch_idx, (inp, target) in enumerate(data_loader):\n",
    "        # Move to the GPU\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Testing batch {batch_idx}\")\n",
    "        inp = inp.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "\n",
    "        # Compute output\n",
    "        output = decoder(encoder(inp))\n",
    "        loss = criterion(output, target)\n",
    "        avg_loss.update(loss.item(), inp.size(0))\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"\\t Test Loss: {loss.item()}\")\n",
    "\n",
    "    return avg_loss.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_timer = utils.Timer()\n",
    "monitor = utils.PerformanceMonitor(args.dump_path)\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "        print(f\"Beginning epoch {epoch}\")\n",
    "        logging.info(f\"Beginning epoch {epoch}...\")\n",
    "\n",
    "        loss_train = train(train_loader, encoder, decoder, optimizer, criterion)\n",
    "        monitor.log(epoch, \"train\", loss_train)\n",
    "        \n",
    "        loss_val = test(valid_loader, encoder, decoder, criterion)\n",
    "        monitor.log(epoch, \"val\", loss_val)\n",
    "        logging.info(\n",
    "            f\"Epoch {epoch} took {epoch_timer.minutes_elapsed()} minutes.\")\n",
    "        epoch_timer.reset()\n",
    "\n",
    "        if loss_val < best_val_loss:\n",
    "            logging.info(\"Saving model\")\n",
    "            save_model(encoder, decoder, args.dump_path, \"best.pt\")\n",
    "            best_val_loss = loss_val\n",
    "save_model(encoder, decoder, args.dump_path, \"final.pt\")\n",
    "logging.info(f\"Code completed in {overall_timer.minutes_elapsed()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_progress = pd.read_csv(os.path.join(args.dump_path,\"performance.csv\"))\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(train_progress.epoch[train_progress[\"stage\"]==\"train\"],train_progress.loss[train_progress[\"stage\"]==\"train\"],label=\"train\")\n",
    "ax.plot(train_progress.epoch[train_progress[\"stage\"]==\"val\"],train_progress.loss[train_progress[\"stage\"]==\"val\"],label=\"validation\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"Dice coefficient loss\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestOrFinal = \"best\"\n",
    "weights_folder = args.dump_path #\"results/field_delineation_10ep/\" #\n",
    "encoderWeights_path = os.path.join(weights_folder,f\"enc_{bestOrFinal}.pt\")\n",
    "decoderWeights_path = os.path.join(weights_folder,f\"dec_{bestOrFinal}.pt\")\n",
    "\n",
    "# load the weigths we saved\n",
    "encoder_trained = encoders._load_swav_pretrained(encoderWeights_path)\n",
    "decoder_trained = decoders.load(args.decoder,encoder)\n",
    "decoder_trained.load_state_dict(torch.load(decoderWeights_path))\n",
    "encoder_trained = encoder_trained.eval()\n",
    "decoder_trained = decoder_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(X0,y,pred,title):    \n",
    "    fig,axes = plt.subplots(1,3)#))\n",
    "    X_ = img_torch2np(invTrans(X0))\n",
    "    y_ = img_torch2np(y)\n",
    "    pred_np= img_torch2np(pred.detach().cpu().squeeze(0))\n",
    "    axes[0].imshow(X_)\n",
    "    axes[0].set_title(\"input\")\n",
    "    axes[1].imshow(y_)\n",
    "    axes[1].set_title(\"true label\")\n",
    "    axes[2].imshow(pred_np)\n",
    "    axes[2].set_title(\"predicted label\")\n",
    "    for i in range(3):\n",
    "        axes[i].axis('off')\n",
    "    fig.suptitle(title,y=0.8,fontsize=20)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "for i in [1,5,7]:\n",
    "    X0,y = train_dataset[i]\n",
    "    X = torch.unsqueeze(X0,0)\n",
    "    X = X.to(DEVICE)\n",
    "    pred = decoder_trained(encoder_trained(X))\n",
    "    pred_prob = torch.sigmoid(pred) # map predicted values to probabilities\n",
    "    plot_prediction(X0,y,pred_prob,\"Train\")\n",
    "    \n",
    "for i in [1,5,7]:\n",
    "    X0,y = valid_dataset[i]\n",
    "    X = torch.unsqueeze(X0,0)\n",
    "    X = X.to(DEVICE)\n",
    "    pred = decoder_trained(encoder_trained(X))\n",
    "    pred_prob = torch.sigmoid(pred) # map predicted values to probabilities\n",
    "    plot_prediction(X0,y,pred_prob,\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(dataloader, encoder,decoder):\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for i, (img, mask) in enumerate(valid_loader):\n",
    "        # Load through the model.\n",
    "        img = img.to(DEVICE)\n",
    "        mask = mask.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            output = encoder(img)\n",
    "            output = decoder(output)\n",
    "            pred_prob = torch.sigmoid(output) #activation function sigmoid function\n",
    "            preds.append(pred_prob .cpu().numpy())#.flatten())\n",
    "            targets.append(mask.cpu().numpy())#.flatten())\n",
    "            \n",
    "    return np.array(preds),np.array(targets)\n",
    "\n",
    "def get_dice_score(preds,targets,smooth = 1):\n",
    "    # https://github.com/sustainlab-group/ParcelDelineation/blob/master/utils/metrics.py\n",
    "    # https://discuss.pytorch.org/t/calculating-dice-coefficient/44154\n",
    "    y_true_f = np.array(targets).flatten()\n",
    "    y_pred_f =np.array(preds).flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def get_IoU(preds,targets,thresh):\n",
    "    preds_copy = np.array(preds).flatten()\n",
    "    targets_f = np.array(targets).flatten()\n",
    "    preds_copy[preds_copy>=thresh] = 1\n",
    "    preds_copy[preds_copy<thresh] = 0\n",
    "    intersection = np.logical_and(preds_copy,targets_f)\n",
    "    union = np.logical_or(preds_copy,targets_f)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    \n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test data and compute prediction\n",
    "\n",
    "test_dataset =  fieldDelineationDataset(test_img_filepaths,test_mask_filepaths,\n",
    "                                        transform=transform_norm)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "preds, targets = get_predictions(test_loader,encoder_trained,decoder_trained)\n",
    "dice_score = get_dice_score(preds,targets,smooth=0.00001)\n",
    "iou = get_IoU(preds,targets, 0.5)\n",
    "print(\"Performanc on test data: Dice score %.3f and IoU %.3f\"%(dice_score,iou))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e9f11f49cd656f291f5777c461e4288f6343aeff66d80fd968f2fc2025425e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
